epoch,train_loss,val_loss
1,1641.9881665874284,4.892217907693098
2,1445.7896242400318,5.687471966943153
3,1359.2117576780902,5.678079271471539
4,1320.228757396369,5.647443801117682
5,1306.018924724322,5.699058526288135
6,1299.284486192298,5.743680786211704
7,1296.4156005919124,5.824355764518034
8,1285.3164413084653,5.8177773713273035
9,1268.1985490321579,5.753839869462369
10,1263.4432214198575,5.948920568321035
11,1261.3847129674587,6.143180487034774
12,1258.6107164559437,6.008658465263515
13,1261.529602117798,6.169564430485072
14,1258.685557863852,6.031940739905359
15,1255.718256485671,6.170165744073818
16,1253.2669362507158,6.328893599151393
17,1250.2961501148525,6.167008904563476
18,1238.7540411041116,5.968274763566212
19,1233.829255467721,6.152686914463465
20,1224.3097769710769,6.205244368407847
21,1215.353444084376,6.364387453784872
22,1214.3199342065452,6.174537201126469
23,1209.1397502695372,6.283042168085188
24,1205.4409199743832,6.624766377883802
25,1203.9555915841026,6.959897153732703
26,1200.489727865344,6.686184032073683
27,1198.5579567868194,6.779856495817363
