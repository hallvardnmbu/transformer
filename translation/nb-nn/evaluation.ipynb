{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Oversettelse fra norsk bokmål til nynorsk\n",
    "\n",
    "OBS: Ekstremt dårlig datasett. Derfor dårlig modell."
   ],
   "id": "2b747f9d05007df2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hyperparameters:\n",
    "```plaintext\n",
    "Hyperparameters(vocab_size=50000, n_encoder_layer=6, n_decoder_layer=8, n_head=8, n_embd=512, dropout=0.1, bias=False, epochs=50, batch_size=128, device='cuda', from_lang='nb', from_path='NbAiLab/norwegian-paws-x', to_lang='nn', to_path='NbAiLab/norwegian-paws-x', tokenizer={'path': 'ltg/norbert3-large', 'k': 500, 'special_symbols': {'[UNK]': 0, '[CLS]': 1, '[SEP]': 2, '[PAD]': 3, '[MASK]': 4, '[BOS]': 5, '[EOS]': 6, '[MASK_0]': 7, '[MASK_1]': 8, '[MASK_2]': 9, '[MASK_3]': 10, '[MASK_4]': 11, '[MASK_5]': 12, '[MASK_6]': 13, '[MASK_7]': 14, '[MASK_8]': 15, '[MASK_9]': 16, '[MASK_10]': 17, '[MASK_11]': 18, '[MASK_12]': 19, '[MASK_13]': 20, '[MASK_14]': 21, '[MASK_15]': 22, '[MASK_16]': 23, '[MASK_17]': 24, '[MASK_18]': 25, '[MASK_19]': 26, '[MASK_20]': 27, '[MASK_21]': 28, '[MASK_22]': 29, '[MASK_23]': 30, '[MASK_24]': 31, '[MASK_25]': 32, '[MASK_26]': 33, '[MASK_27]': 34, '[MASK_28]': 35, '[MASK_29]': 36, '[MASK_30]': 37, '[MASK_31]': 38, '[MASK_32]': 39, '[MASK_33]': 40, '[MASK_34]': 41, '[MASK_35]': 42, '[MASK_36]': 43, '[MASK_37]': 44, '[MASK_38]': 45, '[MASK_39]': 46, '[MASK_40]': 47, '[MASK_41]': 48, '[MASK_42]': 49, '[MASK_43]': 50, '[MASK_44]': 51, '[MASK_45]': 52, '[MASK_46]': 53, '[MASK_47]': 54, '[MASK_48]': 55, '[MASK_49]': 56, '[MASK_50]': 57, '[MASK_51]': 58, '[MASK_52]': 59, '[MASK_53]': 60, '[MASK_54]': 61, '[MASK_55]': 62, '[MASK_56]': 63, '[MASK_57]': 64, '[MASK_58]': 65, '[MASK_59]': 66, '[MASK_60]': 67, '[MASK_61]': 68, '[MASK_62]': 69, '[MASK_63]': 70, '[MASK_64]': 71, '[MASK_65]': 72, '[MASK_66]': 73, '[MASK_67]': 74, '[MASK_68]': 75, '[MASK_69]': 76, '[MASK_70]': 77, '[MASK_71]': 78, '[MASK_72]': 79, '[MASK_73]': 80, '[MASK_74]': 81, '[MASK_75]': 82, '[MASK_76]': 83, '[MASK_77]': 84, '[MASK_78]': 85, '[MASK_79]': 86, '[MASK_80]': 87, '[MASK_81]': 88, '[MASK_82]': 89, '[MASK_83]': 90, '[MASK_84]': 91, '[MASK_85]': 92, '[MASK_86]': 93, '[MASK_87]': 94, '[MASK_88]': 95, '[MASK_89]': 96, '[MASK_90]': 97, '[MASK_91]': 98, '[MASK_92]': 99, '[MASK_93]': 100, '[MASK_94]': 101, '[MASK_95]': 102, '[MASK_96]': 103, '[MASK_97]': 104, '[MASK_98]': 105, '[MASK_99]': 106}, 'vocab_size': 50000, 'tokenizer': PreTrainedTokenizerFast(name_or_path='ltg/norbert3-large', vocab_size=50000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
    "    0: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    3: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    5: AddedToken(\"[BOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    6: AddedToken(\"[EOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    7: AddedToken(\"[MASK_0]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    8: AddedToken(\"[MASK_1]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    9: AddedToken(\"[MASK_2]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    10: AddedToken(\"[MASK_3]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    11: AddedToken(\"[MASK_4]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    12: AddedToken(\"[MASK_5]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    13: AddedToken(\"[MASK_6]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    14: AddedToken(\"[MASK_7]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    15: AddedToken(\"[MASK_8]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    16: AddedToken(\"[MASK_9]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    17: AddedToken(\"[MASK_10]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    18: AddedToken(\"[MASK_11]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    19: AddedToken(\"[MASK_12]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    20: AddedToken(\"[MASK_13]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    21: AddedToken(\"[MASK_14]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    22: AddedToken(\"[MASK_15]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    23: AddedToken(\"[MASK_16]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    24: AddedToken(\"[MASK_17]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    25: AddedToken(\"[MASK_18]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    26: AddedToken(\"[MASK_19]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    27: AddedToken(\"[MASK_20]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    28: AddedToken(\"[MASK_21]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    29: AddedToken(\"[MASK_22]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    30: AddedToken(\"[MASK_23]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    31: AddedToken(\"[MASK_24]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    32: AddedToken(\"[MASK_25]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    33: AddedToken(\"[MASK_26]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    34: AddedToken(\"[MASK_27]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    35: AddedToken(\"[MASK_28]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    36: AddedToken(\"[MASK_29]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    37: AddedToken(\"[MASK_30]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    38: AddedToken(\"[MASK_31]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    39: AddedToken(\"[MASK_32]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    40: AddedToken(\"[MASK_33]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    41: AddedToken(\"[MASK_34]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    42: AddedToken(\"[MASK_35]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    43: AddedToken(\"[MASK_36]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    44: AddedToken(\"[MASK_37]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    45: AddedToken(\"[MASK_38]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    46: AddedToken(\"[MASK_39]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    47: AddedToken(\"[MASK_40]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    48: AddedToken(\"[MASK_41]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    49: AddedToken(\"[MASK_42]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    50: AddedToken(\"[MASK_43]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    51: AddedToken(\"[MASK_44]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    52: AddedToken(\"[MASK_45]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    53: AddedToken(\"[MASK_46]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    54: AddedToken(\"[MASK_47]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    55: AddedToken(\"[MASK_48]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    56: AddedToken(\"[MASK_49]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    57: AddedToken(\"[MASK_50]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    58: AddedToken(\"[MASK_51]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    59: AddedToken(\"[MASK_52]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    60: AddedToken(\"[MASK_53]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    61: AddedToken(\"[MASK_54]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    62: AddedToken(\"[MASK_55]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    63: AddedToken(\"[MASK_56]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    64: AddedToken(\"[MASK_57]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    65: AddedToken(\"[MASK_58]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    66: AddedToken(\"[MASK_59]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    67: AddedToken(\"[MASK_60]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    68: AddedToken(\"[MASK_61]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    69: AddedToken(\"[MASK_62]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    70: AddedToken(\"[MASK_63]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    71: AddedToken(\"[MASK_64]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    72: AddedToken(\"[MASK_65]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    73: AddedToken(\"[MASK_66]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    74: AddedToken(\"[MASK_67]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    75: AddedToken(\"[MASK_68]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    76: AddedToken(\"[MASK_69]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    77: AddedToken(\"[MASK_70]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    78: AddedToken(\"[MASK_71]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    79: AddedToken(\"[MASK_72]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    80: AddedToken(\"[MASK_73]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    81: AddedToken(\"[MASK_74]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    82: AddedToken(\"[MASK_75]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    83: AddedToken(\"[MASK_76]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    84: AddedToken(\"[MASK_77]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    85: AddedToken(\"[MASK_78]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    86: AddedToken(\"[MASK_79]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    87: AddedToken(\"[MASK_80]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    88: AddedToken(\"[MASK_81]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    89: AddedToken(\"[MASK_82]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    90: AddedToken(\"[MASK_83]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    91: AddedToken(\"[MASK_84]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    92: AddedToken(\"[MASK_85]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    93: AddedToken(\"[MASK_86]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    94: AddedToken(\"[MASK_87]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    95: AddedToken(\"[MASK_88]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    96: AddedToken(\"[MASK_89]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    97: AddedToken(\"[MASK_90]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    98: AddedToken(\"[MASK_91]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    99: AddedToken(\"[MASK_92]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    100: AddedToken(\"[MASK_93]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    101: AddedToken(\"[MASK_94]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    102: AddedToken(\"[MASK_95]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    103: AddedToken(\"[MASK_96]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    104: AddedToken(\"[MASK_97]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    105: AddedToken(\"[MASK_98]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    106: AddedToken(\"[MASK_99]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "}}, loss_fn=CrossEntropyLoss(), optimizer={'lr': 0.0001, 'betas': (0.9, 0.98), 'eps': 1e-09}, output_path='./output/')\n",
    "```\n",
    "\n",
    "Transformer architecture:\n",
    "```plaintext\n",
    "Transformer(\n",
    "  (transformer): Transformer(\n",
    "    (encoder): TransformerEncoder(\n",
    "      (layers): ModuleList(\n",
    "        (0-5): 6 x TransformerEncoderLayer(\n",
    "          (self_attn): MultiheadAttention(\n",
    "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
    "          )\n",
    "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
    "          (dropout): Dropout(p=0.1, inplace=False)\n",
    "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
    "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "          (dropout1): Dropout(p=0.1, inplace=False)\n",
    "          (dropout2): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "      )\n",
    "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "    )\n",
    "    (decoder): TransformerDecoder(\n",
    "      (layers): ModuleList(\n",
    "        (0-7): 8 x TransformerDecoderLayer(\n",
    "          (self_attn): MultiheadAttention(\n",
    "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
    "          )\n",
    "          (multihead_attn): MultiheadAttention(\n",
    "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
    "          )\n",
    "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
    "          (dropout): Dropout(p=0.1, inplace=False)\n",
    "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
    "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "          (dropout1): Dropout(p=0.1, inplace=False)\n",
    "          (dropout2): Dropout(p=0.1, inplace=False)\n",
    "          (dropout3): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "      )\n",
    "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
    "    )\n",
    "  )\n",
    "  (src_tok_emb): Embedding(\n",
    "    (embedding): Embedding(50000, 512)\n",
    "  )\n",
    "  (tgt_tok_emb): Embedding(\n",
    "    (embedding): Embedding(50000, 512)\n",
    "  )\n",
    "  (positional_encoding): PositionalEncoding(\n",
    "    (dropout): Dropout(p=0.1, inplace=False)\n",
    "  )\n",
    "  (generator): Linear(in_features=512, out_features=50000, bias=True)\n",
    ")\n",
    "```\n",
    "\n",
    "Vocabulary size: 50000"
   ],
   "id": "4e39b87f05988908"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T19:29:27.842609Z",
     "start_time": "2024-04-16T19:29:25.316980Z"
    }
   },
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "from translator import Translator"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T19:29:36.877358Z",
     "start_time": "2024-04-16T19:29:27.843791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = [\n",
    "    \"Universet\",\n",
    "    \"En stol.\",\n",
    "    \"Boken min er på bordet.\",\n",
    "    \"Jeg liker å sitte på skolen når jeg jobber.\",\n",
    "    \"Ved å høre på forelesninger i fysikk ble jeg veldig trøtt.\",\n",
    "    \"Hvem kan vel unnslippe døden?\",\n",
    "    \"Norges Miljø- og Biovitenskapelige Universitet\"\n",
    "]\n",
    "models = {\n",
    "    \"0 epochs\": Translator(),\n",
    "    \"10 epochs\": torch.load(\"./model-10.pth\", map_location=torch.device('cpu')),\n",
    "    \"30 epochs\": torch.load(\"./model-30.pth\", map_location=torch.device('cpu')),\n",
    "    \"60 epochs\": torch.load(\"./model-60.pth\", map_location=torch.device('cpu')),\n",
    "}"
   ],
   "id": "ada12f4c693d5e6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mac/anaconda3/envs/spesialpensum/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eksempler fra modellene under trening",
   "id": "e2ae8aa7c1ab50ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T19:30:41.629791Z",
     "start_time": "2024-04-16T19:29:36.907563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for state, model in models.items():\n",
    "    model.config.device = \"cpu\"\n",
    "    \n",
    "    print(f\"Modell: {state}\")\n",
    "    for prompt in prompts:\n",
    "        print(f\" Fra: {prompt}\")\n",
    "        print(f\"   > {model(prompt)}\")\n",
    "    print()"
   ],
   "id": "735c9ea726e87c68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell: 0 epochs\n",
      " Fra: Universet\n",
      "   > ##úriaúriaúriaúriaúriaúriaúriaúriaúriaúriaúriaúriaúriaúria\n",
      " Fra: En stol.\n",
      "   > ##omosomosomosomosomosomosomosomosomosomosomosomosomosomosomosomos\n",
      " Fra: Boken min er på bordet.\n",
      "   > ##eteketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketek\n",
      " Fra: Jeg liker å sitte på skolen når jeg jobber.\n",
      "   > khas khas khaseteketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketek\n",
      " Fra: Ved å høre på forelesninger i fysikk ble jeg veldig trøtt.\n",
      "   > 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555 1555\n",
      " Fra: Hvem kan vel unnslippe døden?\n",
      "   > ##eteketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketek\n",
      " Fra: Norges Miljø- og Biovitenskapelige Universitet\n",
      "   > ##eteketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketeketek\n",
      "\n",
      "Modell: 10 epochs\n",
      " Fra: Universet\n",
      "   >  Universetet vart sett i ein av tidlegare hus for Universetet\n",
      " Fra: En stol.\n",
      "   >  Ein annan stad i byen. Han var ein stad i det regionale byen.\n",
      " Fra: Boken min er på bordet.\n",
      "   >  Boka er mykje på å sjå på Manchester.\n",
      " Fra: Jeg liker å sitte på skolen når jeg jobber.\n",
      "   >  Eg prøvde å ha ein god på skulen, men eg held han på ein\n",
      " Fra: Ved å høre på forelesninger i fysikk ble jeg veldig trøtt.\n",
      "   >  Ved å arbeide på fysikk på fysikk er eg mykje mykje enn det.\n",
      " Fra: Hvem kan vel unnslippe døden?\n",
      "   >  Det kan vera ut ein måte å sjå ut ut ut når ho kjem ut.\n",
      " Fra: Norges Miljø- og Biovitenskapelige Universitet\n",
      "   >  Eckhoff brukte eit organisasjon og kulturane som blei sett inn i fengsel og klosterdelagd.\n",
      "\n",
      "Modell: 30 epochs\n",
      " Fra: Universet\n",
      "   >  Universet som inkluderer fotstader i Universet Universet Universtaris\n",
      " Fra: En stol.\n",
      "   >  Den 100re borgmesteren i ein plass i Den statlege plassen.\n",
      " Fra: Boken min er på bordet.\n",
      "   >  Boka er på bordet.\n",
      " Fra: Jeg liker å sitte på skolen når jeg jobber.\n",
      "   >  Eg likte å sitjande på skulen når eg jobbar han.\n",
      " Fra: Ved å høre på forelesninger i fysikk ble jeg veldig trøtt.\n",
      "   >  Ved å høyre høyre senter i fysikk var eg kjent.\n",
      " Fra: Hvem kan vel unnslippe døden?\n",
      "   >  Styremedlemmar går frå døden?\n",
      " Fra: Norges Miljø- og Biovitenskapelige Universitet\n",
      "   >  CLpressa og eit lovleg tårn ved vår\n",
      "\n",
      "Modell: 60 epochs\n",
      " Fra: Universet\n",
      "   >  Universetishet er geet som Universet som Universetis\n",
      " Fra: En stol.\n",
      "   >  Ein kan bli ein statar i skal handla.\n",
      " Fra: Boken min er på bordet.\n",
      "   >  Boka er oms bordet på bordet.\n",
      " Fra: Jeg liker å sitte på skolen når jeg jobber.\n",
      "   >  Eg likar å sitja på skulen når eg jobbar.\n",
      " Fra: Ved å høre på forelesninger i fysikk ble jeg veldig trøtt.\n",
      "   >  Ved å høyre forsking på klinisk forsking vart alle synleg.\n",
      " Fra: Hvem kan vel unnslippe døden?\n",
      "   >  Det kan ta livet av døden å ta resten av farga.\n",
      " Fra: Norges Miljø- og Biovitenskapelige Universitet\n",
      "   >  Tour-kontoret og biografiar ved New York held seg på\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eksempler fra treningsdata",
   "id": "148f4859133eb2a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T19:31:23.630160Z",
     "start_time": "2024-04-16T19:30:41.640187Z"
    }
   },
   "cell_type": "code",
   "source": "dataset, _ = models[\"0 epochs\"]._data()",
   "id": "273cea0f6ed3c9e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since NbAiLab/norwegian-paws-x couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'nb' at /Users/Mac/.cache/huggingface/datasets/NbAiLab___norwegian-paws-x/nb/1.1.0/b59d979a9ee1e04ae424a714479df4baa273396e (last modified on Tue Apr 16 21:28:10 2024).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26e209795d4b45d78d6fcefa3fa77181"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55413e5da07e44a3a301565243fe85fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c456cd8735f249159560a7aef6cb40c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70673bd06a994ff9a7093ecfa477391e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17cba117819c4d7b8852cc5c9321d4fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75f74bbf309547a88d88b026fac7c71a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T19:31:24.015734Z",
     "start_time": "2024-04-16T19:31:23.668015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in torch.random.default_generator.get_state().tolist()[:9]:\n",
    "    print(dataset[\"train\"][\"sentence1\"][i])\n",
    "    print()"
   ],
   "id": "4f429705c9cce1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Den brukes som et mål for absorbert dose, kinetisk energi (utgitt) og kerma (et akronym for spesifikk energi gitt per enhet masse).\n",
      "\n",
      "Flere animatroniske figurer ble også skapt... en gigantisk gås (Galaga) og et animatronisk hode for de marionettede Cernos.\n",
      "\n",
      "Som et team med et seniorstadion, har dere rett til å delta i Scottish Cup.\n",
      "\n",
      "Marsh Creek er en lang biflod av Portneuf River i Bannock County, Idaho.\n",
      "\n",
      "Med en diskret mengde sannsynligheter Formel 1 med betingelsen Formel 2 og Formel 3 et hvilket som helst reelt tall, er Tsallis definert som entropi som\n",
      "\n",
      "(Don Wyatt hadde vært i pingvinene i 1956, og både Eddie og Ray hadde vært med Ray i de senere Colts / Fortunes.)\n",
      "\n",
      "Banach - Mackey topologi og den svake Arens rom topologi er relativt sjelden brukt.\n",
      "\n",
      "Quintus Caecilius Metellus Macedonicus var den andre sønnen til romersk politiker og general Lucius Caecilius Metellus Diadematus.\n",
      "\n",
      "De isodynamiske konjugatene av Fermat-punktene er de isogonale punktene og omvendt.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
