epoch,train_loss,val_loss
1,1087.8726653980434,1.694800821886009
2,819.8240144080047,1.4923622290757674
3,735.6005444042111,1.394126514537004
4,689.48341929287,1.3497933244553229
5,663.397840386941,1.3290815142604533
6,645.6219198864931,1.3232084000985156
7,639.7735725113032,1.3384075414866565
8,635.580580267241,1.3401728141133942
9,627.2556198131065,1.3438407398618106
10,618.8701487286883,1.3420389701267903
11,611.3180971946775,1.3412430161829934
12,604.606901301885,1.3481616290626812
13,598.699590441285,1.3531233393390014
14,593.2476314916327,1.356192147746589
15,588.2403366295055,1.360131307198905
16,583.5234199443794,1.3629425845203755
17,579.0618892019519,1.3692045528044607
18,574.9389853218097,1.3694251776933979
19,570.9126415671416,1.3732722755881035
20,567.1279143355063,1.3750271874199884
21,563.4393286966412,1.3782752340329198
22,559.9239649371145,1.3866719755796215
23,556.47698231642,1.3884174580343918
24,553.1349980540034,1.3896240848129027
25,550.0710686908155,1.3937714582006184
26,546.9328714353145,1.4027175427421734
27,543.761300300619,1.4010997722434955
28,540.1872858137646,1.4016864654377326
29,535.8343310470636,1.4007825632992008
30,532.3000862279825,1.4022085516145497
31,530.3067890187534,1.409931828665537
32,529.5686202356379,1.4185354779588215
33,528.1919610480226,1.4135924143416234
34,526.361070421958,1.4201441956149927
35,524.941389259595,1.422834895052119
36,522.2769450930435,1.427534103273863
37,519.412200353677,1.432684530021862
38,517.2846997225206,1.4293824012215233
39,515.1498219117431,1.4349538183156447
40,512.6892894778487,1.4323231690723237
41,511.04726602950956,1.4366845323341744
42,509.1255777386899,1.444288173606955
43,507.05965547755545,1.4483652079942624
44,505.4421652783458,1.4537664791888179
45,503.6242786713817,1.455387327568389
